# p5_agent_service.py
"""
Agent Service connecting Agent to Pinecone Retriever.
Refactored to use GenAI Lab (OpenAI) and generate Confidence Scores.
"""
from typing import List
import httpx

# --- GenAI Lab / OpenAI Imports ---
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import Tool

# --- Project Imports ---
from p4_retrieval_service import RetrievalAndIndexingService
import p1_config as config

class AgentService:
    def __init__(self, retrieval_service: RetrievalAndIndexingService):
        self.retrieval_service = retrieval_service
        
        # --- SSL Configuration for GenAI Lab ---
        http_client = httpx.Client(verify=False)
        
        self.llm = ChatOpenAI(
            temperature=0.1,
            model=config.LLM_MODEL_NAME,
            base_url="https://genailab.tcs.in",
            api_key=config.GENAI_LLM_API_KEY,
            http_client=http_client
        )
        
        self.last_retrieved_contexts: List[str] = []
        
        self.tools = [self._build_retrieval_tool()]
        self.agent_executor = self._build_executor()
        print("AgentService initialized (GenAI Lab).")

    def _get_agent_prompt(self) -> ChatPromptTemplate:
        """
        Defines the system prompt, enforcing the LLM to generate a Confidence Score.
        """
        return ChatPromptTemplate.from_messages([
            ("system", 
             "You are a helpful assistant. Use the 'Document_Retrieval_Tool' to find answers.\n"
             "1. Answer the question based ONLY on the retrieved context.\n"
             "2. If the tool returns no info, say you don't know.\n"
             "3. CRITICAL: At the very end of your response, provide a 'Confidence Score' (0-100%) "
             "representing how certain you are that the retrieved context answers the user's question.\n\n"
             "Format your output exactly like this:\n"
             "Answer: [Your detailed answer here]\n"
             "Confidence Score: [XX]%" 
             #
            ),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ])

    def _build_retrieval_tool(self) -> Tool:
        def retrieve(query: str) -> str:
            # Use the correct method from p4
            retriever = self.retrieval_service.get_hybrid_retriever()
            docs = retriever.invoke(query)
            
            self.last_retrieved_contexts = [d.page_content for d in docs]
            
            if not docs:
                return "No relevant information found."
            
            context_str = "\n---\n".join([d.page_content for d in docs])
            return f"CONTEXT: {context_str}"

        return Tool(
            name="Document_Retrieval_Tool",
            func=retrieve,
            description="Search the document for specific information."
        )

    def _build_executor(self) -> AgentExecutor:
        prompt = self._get_agent_prompt()
        llm_with_tools = self.llm.bind_tools(self.tools)
        agent = create_tool_calling_agent(llm_with_tools, self.tools, prompt)
        return AgentExecutor(agent=agent, tools=self.tools, verbose=False, handle_parsing_errors=True)

    def run_query(self, query: str):
        print(f"\n--- Query: {query} ---")
        try:
            response = self.agent_executor.invoke({"input": query})
            # The output will now include the Confidence Score text generated by the LLM
            print(f"\n{response['output']}") 
            return response
        except Exception as e:
            print(f"Error: {e}")
            return {"output": "Error executing query."}